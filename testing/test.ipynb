{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, TextClip, ImageClip, CompositeVideoClip, AudioFileClip\n",
    "import pyttsx3 as tts\n",
    "import whisper\n",
    "import requests\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs import generate, save\n",
    "import google.generativeai as genai\n",
    "load_dotenv()\n",
    "\n",
    "client = ElevenLabs(api_key=os.getenv('ELEVENLABS_API_KEY'))\n",
    "gemini_key = os.getenv('GEMINI_API_KEY')\n",
    "genai.configure(api_key=gemini_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_script(prompt, stories):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    default_prompt = \"\"\"from now on return the output as regular text and the story should look\n",
    "                    like it being narrated by someone, For an Example : There was once a boy fishing in the ocean\n",
    "                    and he caught a fish, the fish was very big he was so happy, \n",
    "                    You have to write maximum 1000 characters I want a plain text no symbols just the script, \n",
    "                    also the script content must be in 50 seconds duration, dont include any symbols or special characters,\"\"\"\n",
    "    for i in range(stories):\n",
    "        story = model.generate_content(f\"{default_prompt},{prompt}\")\n",
    "        with open(f'stories/story_{i}.txt', 'w') as f:\n",
    "            f.write(story.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(text):\n",
    "    BASE = 'https://api.unsplash.com/photos/'\n",
    "    PAYLOAD = {\n",
    "        'query': text,\n",
    "        'client_id': os.getenv('UNSPLASH_ACCESS_KEY')\n",
    "    }\n",
    "    response = requests.get(BASE, params=PAYLOAD)\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Scary Mystery Puzzle\"\n",
    "stories = 5\n",
    "generate_script(prompt, stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def speak(text):\n",
    "#     audio = generate(text,\n",
    "#                      voice='Rachel',\n",
    "#                      model = \"eleven_multilingual_v2\")\n",
    "#     save(audio, 'samp.mp3')\n",
    "    \n",
    "def speak(text, file_name):\n",
    "    engine = tts.init()\n",
    "    engine.setProperty('rate', 150)\n",
    "    engine.save_to_file(text, f'audio/{file_name}.mp3')\n",
    "    engine.runAndWait()\n",
    "\n",
    "for i in range(stories):\n",
    "    with open(f'stories/story_{i}.txt', 'r') as f:\n",
    "        text = f.readlines()\n",
    "        speak(text, f'story_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(audio_file):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    data = model.transcribe(audio_file, word_timestamps=True)\n",
    "\n",
    "    start = [data['segments'][i]['words'][j]['start'] for i in range(len(data['segments'])) for j in range(len(data['segments'][i]['words']))]\n",
    "    end = [data['segments'][i]['words'][j]['end'] for i in range(len(data['segments'])) for j in range(len(data['segments'][i]['words']))]\n",
    "    text = [data['segments'][i]['words'][j]['word'] for i in range(len(data['segments'])) for j in range(len(data['segments'][i]['words']))]\n",
    "\n",
    "    return [start, end, text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.tools.subtitles import SubtitlesClip\n",
    "from moviepy.editor import CompositeAudioClip, concatenate_audioclips\n",
    "\n",
    "def generate_video():\n",
    "    for i in range(stories):\n",
    "        with open(f'stories/story_{i}.txt', 'r') as file:\n",
    "            print(f'Generating video for story {i}')\n",
    "            text = file.read()\n",
    "        \n",
    "        words = text.split(' ')\n",
    "\n",
    "        generator = lambda txt: TextClip(txt, \n",
    "                                    fontsize=70, \n",
    "                                    color='white', \n",
    "                                    bg_color='none', \n",
    "                                    font='Arial-Bold',\n",
    "                                    method = 'caption',\n",
    "                                    size = (1920, 1080))\n",
    "\n",
    "        # def clip_generator():\n",
    "        #     for _ in words:\n",
    "        #         yield CompositeVideoClip([ImageClip('Z_1.jpg').set_duration(0.5).set_position('center')], size=(720, 1280))\n",
    "\n",
    "        # clips = concatenate_videoclips(clip_generator(), method=\"compose\")\n",
    "\n",
    "        speech = speech_to_text(f'audio/story_{i}.mp3')\n",
    "        print(f'Accessing speech for story {i}')\n",
    "        subs = [((speech[0][k], speech[1][k]), speech[2][k]) for k in range(len(speech[0]))]\n",
    "\n",
    "        subtitles = SubtitlesClip(subs, generator)\n",
    "        image = ImageClip('Z_1.jpg').set_duration(5).set_position('center')\n",
    "        final_complete = CompositeVideoClip([image, subtitles.set_position(('center', 'center'))])\n",
    "        final_complete.set_audio(f'audio/story_{i}.mp3')\n",
    "        \n",
    "        final_complete.write_videofile(f\"output_{i}.mp4\", fps=24, bitrate = '1000', preset = 'fast', codec = 'h264_nvenc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating video for story 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing speech for story 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_0.mp4.\n",
      "Moviepy - Writing video output_0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      "\u001b[A                                                            \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_0.mp4\n",
      "Generating video for story 1\n",
      "Accessing speech for story 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_1.mp4.\n",
      "Moviepy - Writing video output_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|█▏        | 289/2410 [00:34<04:48,  7.36it/s, now=None]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 35\u001b[0m, in \u001b[0;36mgenerate_video\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m final_complete \u001b[38;5;241m=\u001b[39m CompositeVideoClip([image, subtitles\u001b[38;5;241m.\u001b[39mset_position((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m))])\n\u001b[0;32m     33\u001b[0m final_complete\u001b[38;5;241m.\u001b[39mset_audio(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio/story_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mfinal_complete\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_videofile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1000\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh264_nvenc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<decorator-gen-73>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<decorator-gen-72>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\decorators.py:135\u001b[0m, in \u001b[0;36muse_clip_fps_by_default\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m    130\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[0;32m    131\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[0;32m    132\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[0;32m    133\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m k\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<decorator-gen-71>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\decorators.py:22\u001b[0m, in \u001b[0;36mconvert_masks_to_RGB\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mismask:\n\u001b[0;32m     21\u001b[0m     clip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mto_RGB()\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\video\\VideoClip.py:300\u001b[0m, in \u001b[0;36mVideoClip.write_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m make_audio:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mwrite_audiofile(audiofile, audio_fps,\n\u001b[0;32m    294\u001b[0m                                audio_nbytes, audio_bufsize,\n\u001b[0;32m    295\u001b[0m                                audio_codec, bitrate\u001b[38;5;241m=\u001b[39maudio_bitrate,\n\u001b[0;32m    296\u001b[0m                                write_logfile\u001b[38;5;241m=\u001b[39mwrite_logfile,\n\u001b[0;32m    297\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    298\u001b[0m                                logger\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[1;32m--> 300\u001b[0m \u001b[43mffmpeg_write_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbitrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwrite_logfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_logfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maudiofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudiofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mffmpeg_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffmpeg_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_temp \u001b[38;5;129;01mand\u001b[39;00m make_audio:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(audiofile):\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py:220\u001b[0m, in \u001b[0;36mffmpeg_write_video\u001b[1;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FFMPEG_VideoWriter(filename, clip\u001b[38;5;241m.\u001b[39msize, fps, codec \u001b[38;5;241m=\u001b[39m codec,\n\u001b[0;32m    214\u001b[0m                             preset\u001b[38;5;241m=\u001b[39mpreset, bitrate\u001b[38;5;241m=\u001b[39mbitrate, logfile\u001b[38;5;241m=\u001b[39mlogfile,\n\u001b[0;32m    215\u001b[0m                             audiofile\u001b[38;5;241m=\u001b[39maudiofile, threads\u001b[38;5;241m=\u001b[39mthreads,\n\u001b[0;32m    216\u001b[0m                             ffmpeg_params\u001b[38;5;241m=\u001b[39mffmpeg_params) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m    218\u001b[0m     nframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(clip\u001b[38;5;241m.\u001b[39mduration\u001b[38;5;241m*\u001b[39mfps)\n\u001b[1;32m--> 220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwithmask\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\Clip.py:472\u001b[0m, in \u001b[0;36mClip.iter_frames\u001b[1;34m(self, fps, with_times, logger, dtype)\u001b[0m\n\u001b[0;32m    470\u001b[0m logger \u001b[38;5;241m=\u001b[39m proglog\u001b[38;5;241m.\u001b[39mdefault_bar_logger(logger)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m logger\u001b[38;5;241m.\u001b[39miter_bar(t\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration, \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mfps)):\n\u001b[1;32m--> 472\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (frame\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype):\n\u001b[0;32m    474\u001b[0m         frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mastype(dtype)\n",
      "File \u001b[1;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[1;34m(f, *a, **kw)\u001b[0m\n\u001b[0;32m     85\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[0;32m     86\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[0;32m     87\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[0;32m     88\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m kw\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\video\\compositing\\CompositeVideoClip.py:111\u001b[0m, in \u001b[0;36mCompositeVideoClip.__init__.<locals>.make_frame\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    109\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbg\u001b[38;5;241m.\u001b[39mget_frame(t)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplaying_clips(t):\n\u001b[1;32m--> 111\u001b[0m         f \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblit_on\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\video\\VideoClip.py:564\u001b[0m, in \u001b[0;36mVideoClip.blit_on\u001b[1;34m(self, picture, t)\u001b[0m\n\u001b[0;32m    560\u001b[0m     pos[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m D[pos[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m    562\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, pos)\n\u001b[1;32m--> 564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mblit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mismask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\moviepy\\video\\tools\\drawing.py:49\u001b[0m, in \u001b[0;36mblit\u001b[1;34m(im1, im2, pos, mask, ismask)\u001b[0m\n\u001b[0;32m     46\u001b[0m     blit_region \u001b[38;5;241m=\u001b[39m new_im2[yp1:yp2, xp1:xp2]\n\u001b[0;32m     47\u001b[0m     new_im2[yp1:yp2, xp1:xp2] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m mask \u001b[38;5;241m*\u001b[39m blitted \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m mask) \u001b[38;5;241m*\u001b[39m blit_region)\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_im2\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m ismask) \u001b[38;5;28;01melse\u001b[39;00m new_im2\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mspeech\u001b[49m[\u001b[38;5;241m0\u001b[39m])):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(((speech[\u001b[38;5;241m0\u001b[39m][l], speech[\u001b[38;5;241m1\u001b[39m][l]), speech[\u001b[38;5;241m2\u001b[39m][l]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech' is not defined"
     ]
    }
   ],
   "source": [
    "for l in range(len(speech[0])):\n",
    "    print(((speech[0][l], speech[1][l]), speech[2][l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package tortoise:\n",
      "\n",
      "NAME\n",
      "    tortoise\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    api_fast\n",
      "    do_tts\n",
      "    eval\n",
      "    get_conditioning_latents\n",
      "    is_this_from_tortoise\n",
      "    models (package)\n",
      "    read\n",
      "    read_fast\n",
      "    tts_stream\n",
      "    utils (package)\n",
      "\n",
      "FILE\n",
      "    d:\\projects\\video-generator\\myenv\\lib\\site-packages\\tortoise_tts-3.0.0-py3.11.egg\\tortoise\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tortoise as t\n",
    "from tortoise import api_fast\n",
    "\n",
    "help(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepspeed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tts \u001b[38;5;241m=\u001b[39m \u001b[43mapi_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextToSpeech\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_deepspeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m pcm_audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts_with_preset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour text here\u001b[39m\u001b[38;5;124m\"\u001b[39m, preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfast\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\tortoise_tts-3.0.0-py3.11.egg\\tortoise\\api_fast.py:216\u001b[0m, in \u001b[0;36mTextToSpeech.__init__\u001b[1;34m(self, autoregressive_batch_size, models_dir, enable_redaction, kv_cache, use_deepspeed, half, device, tokenizer_vocab_file, tokenizer_basic)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive \u001b[38;5;241m=\u001b[39m UnifiedVoice(max_mel_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m604\u001b[39m, max_text_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m402\u001b[39m, max_conditioning_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m    212\u001b[0m                                   model_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m    213\u001b[0m                                   heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, number_text_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m, start_text_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m, checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    214\u001b[0m                                   train_solo_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(get_model_path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoregressive.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, models_dir)), strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoregressive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_init_gpt2_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_deepspeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_deepspeed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhifi_decoder \u001b[38;5;241m=\u001b[39m HifiganGenerator(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, resblock_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m resblock_dilation_sizes \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m], [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m], [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m]], resblock_kernel_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m    220\u001b[0m upsample_kernel_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m], upsample_initial_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, upsample_factors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    221\u001b[0m cond_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    222\u001b[0m hifi_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(get_model_path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhifidecoder.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32md:\\projects\\Video-Generator\\myenv\\Lib\\site-packages\\tortoise_tts-3.0.0-py3.11.egg\\tortoise\\models\\autoregressive.py:380\u001b[0m, in \u001b[0;36mUnifiedVoice.post_init_gpt2_config\u001b[1;34m(self, use_deepspeed, kv_cache, half)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model \u001b[38;5;241m=\u001b[39m GPT2InferenceModel(\n\u001b[0;32m    371\u001b[0m     gpt_config,\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m     kv_cache\u001b[38;5;241m=\u001b[39mkv_cache,\n\u001b[0;32m    378\u001b[0m )\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_deepspeed \u001b[38;5;129;01mand\u001b[39;00m half \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdeepspeed\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_engine \u001b[38;5;241m=\u001b[39m deepspeed\u001b[38;5;241m.\u001b[39minit_inference(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model,  \n\u001b[0;32m    382\u001b[0m                                             mp_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    383\u001b[0m                                             replace_with_kernel_inject\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    384\u001b[0m                                             dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_engine\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'deepspeed'"
     ]
    }
   ],
   "source": [
    "tts = api_fast.TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "pcm_audio = tts.tts_with_preset(\"your text here\", preset='fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
